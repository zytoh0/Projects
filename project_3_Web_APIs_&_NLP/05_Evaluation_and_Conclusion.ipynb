{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: Reddit - Evaluation and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Notebook 5\n",
    "\n",
    "The fifth notebook will include evaluation of the production model, conclusion and the recommendations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize, WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Import model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Import Evaluations\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Evaluation - Baseline Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline score we are using to evaluate this model is accuracy. The solution to our problem statement is to pull out the top 20 features of each reddit to identify interest of cat and dog owners in order to for our stakeholder to push out new business ventures for this group of audience. By having a high accuracy, the features identified will be relevant to the audience and insightful solutions can be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Evaulation - Relevant Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four possible relevant metrics for our production model:\n",
    "* Accuracy\n",
    "* Sensitivity\n",
    "* Specificity\n",
    "* Precision\n",
    "\n",
    "Accuracy measures how high the true positive and true negatives is. When the accuracy is high, the top features for each subreddit will be from the correct subreddit group and we can then correctly draw our insights from thus this metrics will be our baseline score.\n",
    "\n",
    "Sensitivity measures how much of the positives are true positives. Since we are not looking at only one class but both classes of both cats and dogs, this metrics will not be able to give us a true success of our production model.\n",
    "\n",
    "Specificity like sensitivity measures only one class. Specificity measures the amount of true negatives among all the negatives. The reason to reject this metrics as a baseline score is the same of rejecting sensitivity.\n",
    "\n",
    "Precision measures the ability of a classification model to identify only the relevant data points. It is calculated how much of all the classified positives are true positives. This is a better evaluation metrics as compare to sensitivity and specificity but it still only measure one class thus is not the best evaluation metric for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Evaulation - Interpretation of Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original list of english stop words in SkLearn Library\n",
    "text.ENGLISH_STOP_WORDS\n",
    "\n",
    "# Create list for new stop words\n",
    "add_stop_words = ['im', 'does']\n",
    "\n",
    "# Joining new list of stop words to list in SKLearn Library\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Print to check\n",
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to find the train and test accuracy scores of the models with 5 fold cross validation\n",
    "def report_error(model, X1, y1, X2, y2):\n",
    "    model.fit(X1, y1)\n",
    "    print('The accuracy train score for', model, 'is', cross_val_score(model, X1, y1, cv=5).mean(),'.')\n",
    "    print('The accuracy test score for',model, 'is', cross_val_score(model, X2, y2, cv=5).mean(),'.')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy train score for MultinomialNB() is 0.9228375873885936 .\n",
      "The accuracy test score for MultinomialNB() is 0.9112072605889174 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reloading the data and implement what we found above.\n",
    "# Stemming\n",
    "df_model = pd.read_csv('./dataset/cleaned.csv') \n",
    "\n",
    "# Instantiate PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Create function to stem\n",
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.split()\n",
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "df_model['title'] = pd.DataFrame(df_model['title'].apply(stem_sentences))\n",
    "\n",
    "# Count Vectoriser with the additional stop words\n",
    "X = df_model['title']\n",
    "\n",
    "# Instantiate a CountVectorizer with the new added stop words and min df = 3 and ngram range from 1 to 3.\n",
    "cvec = CountVectorizer(stop_words = stop_words, min_df = 1, max_df = 0.35,  ngram_range=(1,1), max_features = 3500)\n",
    "\n",
    "# Fit the vectorizer on our corpus and transform it.\n",
    "X_vec = cvec.fit_transform(X)\n",
    "\n",
    "# Create a dataframe after count vectoriser\n",
    "df_vec_model = pd.DataFrame(X_vec.todense(), columns = cvec.get_feature_names())\n",
    "\n",
    "# Remove the subreddit columns and add back the original columns\n",
    "df_vec_model.drop(columns =['subreddit'], inplace = True)\n",
    "df_vec_model = pd.concat([df_vec_model, df_model[['subreddit', 'emoji', 'word_count', 'title_length']]], axis=1)\n",
    "\n",
    "# Define target variable\n",
    "y = df_vec_model.pop('subreddit')\n",
    "X = df_vec_model\n",
    "\n",
    "# Instantiate Multinomial Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Redefine training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "report_error(nb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dog', -4.544803418066204),\n",
       " ('help', -6.589812763324556),\n",
       " ('puppi', -6.793908119668071),\n",
       " ('breed', -7.214582646439764),\n",
       " ('need', -7.267692471753713),\n",
       " ('old', -7.279887744847531),\n",
       " ('ha', -7.295344003084223),\n",
       " ('advic', -7.386612517197171),\n",
       " ('theyv', -7.428430456880493),\n",
       " ('doe', -7.561453590281876),\n",
       " ('food', -7.598724985079107),\n",
       " ('new', -7.598724985079107),\n",
       " ('trail', -7.6731575798618765),\n",
       " ('wherev', -7.710198851542226),\n",
       " ('anyon', -7.763480218155163),\n",
       " ('ye', -7.809289754186457),\n",
       " ('ani', -7.814511698167609),\n",
       " ('like', -7.814511698167609),\n",
       " ('just', -7.846429301135914),\n",
       " ('look', -7.913493531716459)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_salient_words(nb_clf, vect, class_ind):\n",
    "    words = cvec.get_feature_names()\n",
    "    zipped = list(zip(words, nb_clf.feature_log_prob_[class_ind]))\n",
    "    sorted_zip = sorted(zipped, key=lambda t: t[1], reverse=True)\n",
    "    return sorted_zip\n",
    "\n",
    "neg_salient_top_20 = get_salient_words(nb, cvec, 0)[:20]\n",
    "pos_salient_top_20 = get_salient_words(nb, cvec, 1)[:20]\n",
    "\n",
    "pos_salient_top_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', -5.237643947111158),\n",
       " ('theyv', -6.164994532451706),\n",
       " ('zuko', -6.484474313936721),\n",
       " ('new', -6.983244086010304),\n",
       " ('ye', -6.989461722621175),\n",
       " ('hi', -7.058306104984681),\n",
       " ('love', -7.062770398113367),\n",
       " ('like', -7.122696159044555),\n",
       " ('just', -7.168876904107915),\n",
       " ('vs', -7.276451034394055),\n",
       " ('kitten', -7.307395838243477),\n",
       " ('littl', -7.4582187279780605),\n",
       " ('ha', -7.498902304614504),\n",
       " ('look', -7.563210171847235),\n",
       " ('kitti', -7.631939503999416),\n",
       " ('day', -7.6559406560989585),\n",
       " ('boy', -7.710007877369234),\n",
       " ('old', -7.718591621060626),\n",
       " ('help', -7.72724968380374),\n",
       " ('babi', -7.762651610854657)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_salient_top_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final model achieves an accuracy of higher than 90% accuracy. This gives us the confidence that the word features extracted are reliable to derive insights from.\n",
    "\n",
    "The top 20 word features do give us an idea of the interest of cat and dog owners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Evaulation - Domain Knowledge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appying domain knowledge for each subreddit by gaining insights from the word features.\n",
    "\n",
    "**Dog Features**\n",
    "* Puppi - Puppies are ranked 3rd in importance which shows that most dog owners own new born dogs. At this stage, much care is required. A care service can be provided to cater to dogs of a certain young age or training for dog owners to raise their puppies.\n",
    "* Breed - There are many breeds in dogs. A premium service can be formed to search for exquisite dog breeds to sell to owners who are interested to pay a high price.\n",
    "* help/need/advice - This 3 keywords implies that dog owners meet a lot of problems with their dogs. A paid hotline can be setup to answer and address these issues.\n",
    "* trail - This interesting word tells us that dog owners like to walk their dogs and are looking for trails to do that. An interest group can be created where trails with beautiful scenaries can be recommended.\n",
    "* food - This word features suggest that dog owners are concern about the overall health of dogs and want to feed them properly.\n",
    "\n",
    "**Cat Features**\n",
    "* love/like - This 2 features can be interpreted 2 ways. First it can be the expression of cat owners to their cats. As seen during EDA, cat owners tend to want to dress up their cats more. They are more expressive and post a lot of pictures about their cats. Secondly, it can be intrepreted as what their cats love. A grooming service can be setup for cat owners to better express their love for their cats by dressing and grooming them. It is also possible to open a toy and food shop to sell things that cats love.\n",
    "* kitten - Similar to the above, the word kitten means that a lot of cat owners own their cat when they are young and similar services can be created to baby cats.\n",
    "* vs - This word feature tells us that cat owners like to compare. When setting up e-commerce shop for cats, it is good to include a comparision feature for the stuff they sell.\n",
    "* new - This word features suggest that cat owners like to buy new stuff for their cats. While dog owners are more concern about the needs of their dogs, cat owners like to spend on their cats by buying new stuff for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Evaulation - Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descriptive**\n",
    "The following were derived during cleaning and EDA:\n",
    "* Cat subreddits post much higher emoji and pictures than dog owners.\n",
    "* Dog subreddits have higher word_count as compare to cat owners.\n",
    "\n",
    "**Inferential**\n",
    "* The features drawn all have negative coefficients as Naive Bayers is one directional. This however does not prevent us from understanding the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Conclusion - Overall Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the following steps has help us reach the solution to our problem statement:\n",
    "* Data collection help us understand the main difference between cat and dog owners in that cat owners like to post pictures. this helps gives us confidence when deriving the recomeendations at the end.\n",
    "* Date Cleaning help us organise the data better and to create new features for the model such as emoji and word count. This helps improve the overall accuracy scores of our production model after optimisation.\n",
    "* Preprocessing helps us reduce the features through stemming and addition of stopwords. This helps improve the model in reaching higher accuracy.\n",
    "* Model Selection helps us find the best model after fitting 7 classification models and optimising the top 2. This then led us to the top features to give recommendations to our stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Conclusion - How to obtain Recommendations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Refer to 1.4 above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Conclusion - Final Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following improvements can be made for our model:\n",
    "* For modeling rigor, literal subreddit name references should have been removed as individual words (e.g. \"dog\", \"cat\") were left in earlier on.\n",
    "* Having posts with more unique words helps to distinguish between spam and ham but;\n",
    "* Not all posts with unique words are relevant, so we have to focus more on the coefficient of frequently appearing words\n",
    "* Perhaps this project could be improved by performing a form of sentiment analysis on the data in future studies. Lastly, though this model scored only around ~ 90% accuracy on testing data, this model still predicts much better than the baseline (~ 50.6%) and might be helpful in differentiating between dogs and cats.\n",
    "* Further analysis can be done on the emojis within the titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Conclusion -  Does Conclusion Answers Problem Statement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The production model hits the accuracy of 90% and the features gave us business recommendations. This is the 2 targets we set out to achieve at the start of the project thus our problem statement is address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 Conclusion - Benefits for Stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefits to stakeholders are 2 fold:\n",
    "* 1. The production model can be use constantly to understand the trends of dogs and cat owners.\n",
    "* 2. A variety of business recommendations are provided in 1.4 above for possible business ventures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 2.6 Conclusion - Future Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward:\n",
    "* The same production model can be applied to other subreddit to obtain the interest of other types of pet owners.\n",
    "* Explore other forums that are more local e.g. Hardwarezone because Reddit posts are more global and may not attune well to local context even though CatDog wants to reach out to an international clientele. Starting small within the local context would be a better way to 'taste' the market first."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
